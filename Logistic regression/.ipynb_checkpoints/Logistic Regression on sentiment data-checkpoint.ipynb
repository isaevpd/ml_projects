{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load json file with 'important words'\n",
    "with open('important_words.json') as f:\n",
    "    important_words = json.loads(next(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\n",
      "2. Nature's Lullabies Second Year Sticker Calendar\n",
      "3. Nature's Lullabies Second Year Sticker Calendar\n",
      "4. Lamaze Peekaboo, I Love You\n",
      "5. SoftPlay Peek-A-Boo Where's Elmo A Children's Book\n",
      "6. Our Baby Girl Memory Book\n",
      "7. Hunnt&reg; Falling Flowers and Birds Kids Nursery Home Decor Vinyl Mural Art Wall Paper Stickers\n",
      "8. Blessed By Pope Benedict XVI Divine Mercy Full Color Medal\n",
      "9. Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)\n",
      "10. Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)\n"
     ]
    }
   ],
   "source": [
    "# print out first 10 product names\n",
    "for i, name in enumerate(products['name'][:10]):\n",
    "    print '{}. {}'.format(i+1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews is 26579.\n",
      "Number of negative reviews is 26493.\n"
     ]
    }
   ],
   "source": [
    "# count number of positive/negative reviews\n",
    "positive, negative = products['sentiment'].value_counts()\n",
    "print 'Number of positive reviews is {}.'.format(positive)\n",
    "print 'Number of negative reviews is {}.'.format(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill NA values with empty strings\n",
    "products = products.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new column with occurrences of important words\n",
    "# takes some time\n",
    "for i, word in enumerate(important_words):\n",
    "#     print 'word is {}, {} words left.'.format(word, len(important_words) - (i+1))\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['contains_perfect'] = products['perfect'].apply(lambda n : 1 if n >= 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 2: How many reviews in amazon_baby_subset.gl contain the word perfect?\n",
    "print sum(products['contains_perfect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    # prevent adding constant to the original dataframe\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return (feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 3\n",
    "# Consider the feature_matrix that was obtained by converting our data to NumPy format.\n",
    "# How many features are there in the feature_matrix?\n",
    "print feature_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 4\n",
    "# Assuming that the intercept is present,\n",
    "# how does the number of features in feature_matrix relate to the number of features in the logistic regression model?\n",
    "# Let x = [number of features in feature_matrix] and y = [number of features in logistic regression model].\n",
    "print 'y = x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    '''\n",
    "    produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "    estimate ranges between 0 and 1.\n",
    "    '''\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1. / (1 + np.exp(-score))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    return np.dot(errors, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in xrange(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, j])\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] += (step_size * derivative)\n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_coefficients = np.zeros(194)\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_ = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 5:\n",
    "# Run your logistic regression solver with provided parameters.\n",
    "# As each iteration of gradient ascent passes, does the log-likelihood increase or decrease?\n",
    "print 'It increases.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix, coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 6: We make predictions using the weights just learned.\n",
    "# How many reviews were predicted to have positive sentiment?\n",
    "print sum(scores > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 7: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)\n",
    "def predict(p):\n",
    "    return 1 if p > 0 else -1\n",
    "\n",
    "predict = np.vectorize(predict)\n",
    "predictions = predict(scores)\n",
    "\n",
    "accuracy = sum(predictions == sentiment) / float(len(scores))\n",
    "print round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = list(coef_[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 8: \n",
    "# We look at \"most positive\" words, the words that correspond most strongly with positive reviews.\n",
    "# Which of the following words is not present in the top 10 \"most positive\" words?\n",
    "for i, (word, coef) in enumerate(word_coefficient_tuples[:10]):\n",
    "    print '{}. {}'.format(i+1, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Cheap is not one of the 10 most positive words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question 9:\n",
    "# Similarly, we look at \"most negative\" words, the words that correspond most strongly with negative reviews.\n",
    "# Which of the following words is not present in the top 10 \"most negative\" words?\n",
    "for i, (word, coef) in enumerate(word_coefficient_tuples[-10:]):\n",
    "    print '{}. {}'.format(i+1, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Need is not one of the 10 most positive words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
